{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Layer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps:\n",
    " - Define Structure\n",
    " - initialize parameters\n",
    " - Forward Propagation\n",
    "   $$Z^{[1]} =  W^{[1]} X + b^{[1]} $$ \n",
    "   $$A^{[1]} = \\tanh(Z^{[1]}) $$\n",
    "   $$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]} $$\n",
    "   $$\\hat{Y} = A^{[2]} = \\sigma(Z^{[2]}) $$\n",
    "\n",
    "\n",
    " - compute cost\n",
    "    - $$J = - \\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(} \\small y^{(i)}\\log\\left(\\hat{y}^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- \\hat{y}^{[2] (i)}\\right) \\large{)} \\small $$\n",
    " - Backward Propagation\n",
    "  ---------------------------------------------------------------------\n",
    "  $$dZ^{[2]} =  A^{[2]} - Y  $$ \n",
    "  $$dW^{[2]} = \\frac {1} {m} dZ^{[2]} A^{[1]T}  $$\n",
    "  $$db^{[2]} = \\frac {1} {m} \\sum\\limits_{i = 1}^{m} dZ^{[2]}  $$\n",
    "  ---------------------------------------------------------------------\n",
    "  $$dW^{[2]} = \\frac {1} {m} dZ^{[2]} A^{[1]T}  $$\n",
    "  $$dZ^{[2]} = W^{[2]} A^{[1]} + b^{[2]} $$\n",
    "  $$\\hat{Y} = A^{[2]} = \\sigma(Z^{[2]}) $$\n",
    " - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Structure and initializing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer(input_dim:int, hidden:int, output_dim:int):\n",
    "    W1 = tf.random.normal([hidden, input_dim], dtype=tf.float64)\n",
    "    b1 = tf.zeros([hidden, 1], dtype=tf.float64)\n",
    "    W2 = tf.random.normal([output_dim, hidden], dtype=tf.float64)\n",
    "    b2 = tf.zeros([output_dim, 1], dtype=tf.float64)\n",
    "    return {\n",
    "        'W1':W1, \"b1\": b1, \"W2\": W2, \"b2\": b2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer(2, 4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward propagation\n",
    "---------------------------------------\n",
    "   $$Z^{[1]} =  W^{[1]} X + b^{[1]} $$ \n",
    "   $$A^{[1]} = \\tanh(Z^{[1]}) $$\n",
    "   $$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]} $$\n",
    "   $$\\hat{Y} = A^{[2]} = \\sigma(Z^{[2]}) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(params: dict, X:tf.Tensor):\n",
    "    W1, b1, W2, b2 = params.values()\n",
    "    Z1 = tf.tensordot(W1, X, axes=1) + b1\n",
    "    A1 = tf.nn.tanh(Z1)\n",
    "    Z2 = tf.tensordot(W2, A1, axes=1) + b2\n",
    "    A2 = tf.nn.sigmoid(Z2)\n",
    "    state = {\n",
    "        \"Z1\":Z1, \"A1\":A1, \"Z2\":Z2, \"A2\":A2\n",
    "    }\n",
    "    return A2, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.Variable(\n",
    "    [\n",
    "        [2, 3, 4, 5, 6],\n",
    "        [7, 2, 3, 4, 8],\n",
    "    ], dtype=tf.float64\n",
    ")\n",
    "Y = tf.Variable([[1, 1, 0, 0, 1]], dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = initializer(2, 4, 1)\n",
    "forward_prop(params, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(params: dict, state: dict, X: tf.Tensor, Y: tf.Tensor):\n",
    "    W1, b1, W2, b2 = params.values()\n",
    "    Z1, A1, Z2, A2 = state.values()\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * tf.tensordot(dZ2, tf.transpose(A1), axes=1)\n",
    "    db2 = (1/m) * tf.reduce_sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = tf.tensordot(tf.transpose(W2), dZ2, axes=1) * (1 - tf.pow(A1, 2))\n",
    "    dW1 = (1/m) * tf.tensordot(dZ1, tf.transpose(X), axes=1)\n",
    "    db1 = (1/m) * tf.reduce_sum(dZ1, axis=1, keepdims=True)\n",
    "    grads = {\n",
    "        'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2\n",
    "    }\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = initializer(2, 4, 1)\n",
    "A2, state = forward_prop(params, X)\n",
    "back_prop(params, state, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Parameters:\n",
    "$$ w1 = w1 - {\\alpha} * \\frac{\\partial J}{\\partial w1} $$\n",
    "$$ b1 = b1- {\\alpha}  * \\frac{\\partial J}{\\partial b1} $$\n",
    "$$ w2 = w2 - {\\alpha} * \\frac{\\partial J}{\\partial w2} $$\n",
    "$$ b2 = b2- {\\alpha}  * \\frac{\\partial J}{\\partial b2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(params: dict, grads: dict, alpha: float = 0.01):\n",
    "    W1, b1, W2, b2 = params.values()\n",
    "    dW1, db1, dW2, db2 = grads.values()\n",
    "    W1 = W1 - (alpha * dW1)\n",
    "    b1 = b1 - (alpha * db1)\n",
    "    W2 = W2 - (alpha * dW2)\n",
    "    b2 = b2 - (alpha * db2)\n",
    "    return dict(W1=W1, b1=b1, W2=W2, b2=b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = initializer(2, 4, 1)\n",
    "A2, state = forward_prop(params, X)\n",
    "grads = back_prop(params, state, X, Y)\n",
    "update(params, grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNN:\n",
    "    \"\"\"\n",
    "    Parameters: input_dim : No of Fetures, hidden_dim : neuron in hidden layer, \n",
    "    output_dim: no of output neuron\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, hidden: int, output_dim: int, alpha: float = 0.01):\n",
    "        self.params = self.initialize_params(input_dim, hidden, output_dim)\n",
    "        self.state = dict()\n",
    "        self.grads = dict()\n",
    "        self.cost = None\n",
    "        self.alpha = alpha\n",
    "        self.losses = []\n",
    "\n",
    "    def initialize_params(self, input_dim: int, hidden: int, output_dim: int):\n",
    "        W1 = tf.random.normal([hidden, input_dim], dtype=tf.float64)\n",
    "        b1 = tf.zeros([hidden, 1], dtype=tf.float64)\n",
    "        W2 = tf.random.normal([output_dim, hidden], dtype=tf.float64)\n",
    "        b2 = tf.zeros([output_dim, 1], dtype=tf.float64)\n",
    "        return {\n",
    "            'W1': W1, \"b1\": b1, \"W2\": W2, \"b2\": b2\n",
    "        }\n",
    "\n",
    "    def forward_prop(self,  X: tf.Tensor):\n",
    "        W1, b1, W2, b2 = self.params.values()\n",
    "        Z1 = tf.tensordot(W1, X, axes=1) + b1\n",
    "        A1 = tf.nn.tanh(Z1)\n",
    "        Z2 = tf.tensordot(W2, A1, axes=1) + b2\n",
    "        A2 = tf.nn.sigmoid(Z2)\n",
    "        state = {\n",
    "            \"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2\n",
    "        }\n",
    "        return A2, state\n",
    "\n",
    "    def compute_cost(self, Y: tf.Tensor, Yhat: tf.Tensor):\n",
    "        m = Yhat.shape[1]\n",
    "        loss = tf.reduce_sum((Y * tf.math.log(Yhat)) +\n",
    "                             ((1-Y) * tf.math.log(1-Yhat)))\n",
    "        cost = (-1/m) * loss\n",
    "        return cost\n",
    "\n",
    "    def back_prop(self, X: tf.Tensor, Y: tf.Tensor):\n",
    "        W1, b1, W2, b2 = self.params.values()\n",
    "        Z1, A1, Z2, A2 = self.state.values()\n",
    "        m = Y.shape[1]\n",
    "\n",
    "        dZ2 = A2 - Y\n",
    "        dW2 = (1/m) * tf.tensordot(dZ2, tf.transpose(A1), axes=1)\n",
    "        db2 = (1/m) * tf.reduce_sum(dZ2, axis=1, keepdims=True)\n",
    "        dZ1 = tf.tensordot(tf.transpose(W2), dZ2, axes=1) * (1 - tf.pow(A1, 2))\n",
    "        dW1 = (1/m) * tf.tensordot(dZ1, tf.transpose(X), axes=1)\n",
    "        db1 = (1/m) * tf.reduce_sum(dZ1, axis=1, keepdims=True)\n",
    "        grads = {\n",
    "            'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2\n",
    "        }\n",
    "        return grads\n",
    "\n",
    "    def state_update(self):\n",
    "        W1, b1, W2, b2 = self.params.values()\n",
    "        dW1, db1, dW2, db2 = self.grads.values()\n",
    "        W1 = W1 - (self.alpha * dW1)\n",
    "        b1 = b1 - (self.alpha * db1)\n",
    "        W2 = W2 - (self.alpha * dW2)\n",
    "        b2 = b2 - (self.alpha * db2)\n",
    "        return dict(W1=W1, b1=b1, W2=W2, b2=b2)\n",
    "\n",
    "    def optimize(self, X: tf.Tensor, Y: tf.Tensor, validation: tuple, epochs=100):\n",
    "        for epoch in range(epochs):\n",
    "            A2, self.state = self.forward_prop(X)\n",
    "            self.cost = self.compute_cost(Y, A2)\n",
    "            self.grads = self.back_prop(X, Y)\n",
    "            self.params = self.state_update()\n",
    "\n",
    "            # Model State\n",
    "            if epoch % 50 == 0:\n",
    "                self.losses.append(self.cost)\n",
    "                Xv, Yv = validation\n",
    "                train_acc = 100 - \\\n",
    "                    (tf.reduce_mean(tf.abs(tf.subtract(self.predict(X), Y)) * 100))\n",
    "                test_acc = 100 - \\\n",
    "                    (tf.reduce_mean(tf.abs(tf.subtract(self.predict(Xv), Yv)) * 100))\n",
    "                print(\n",
    "                    f\"Epoch: {epoch} || Cost: {self.cost:.4f} || Train Acc: {train_acc:.2f}% || Test Acc: {test_acc:.2f}%\")\n",
    "        return self.params, self.cost\n",
    "\n",
    "    def predict(self, X: tf.Tensor):\n",
    "        W1, b1, W2, b2 = self.params.values()\n",
    "        Z1 = tf.tensordot(W1, X, axes=1) + b1\n",
    "        A1 = tf.nn.tanh(Z1)\n",
    "        Z2 = tf.tensordot(W2, A1, axes=1) + b2\n",
    "        A2 = tf.nn.sigmoid(Z2)\n",
    "        return tf.round(A2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test MOdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, Y = load_breast_cancer(return_X_y=True)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 426])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = StandardScaler().fit_transform(xtrain)\n",
    "xtrain = tf.Variable(xtrain, dtype=tf.float64)\n",
    "ytrain = tf.Variable([ytrain], dtype=tf.float64)\n",
    "xtrain = tf.transpose(xtrain)\n",
    "xtrain.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 143])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = StandardScaler().fit_transform(xtest)\n",
    "xtest = tf.Variable(xtest, dtype=tf.float64)\n",
    "ytest = tf.Variable([ytest], dtype=tf.float64)\n",
    "xtest = tf.transpose(xtest)\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 || Cost: 0.4065 || Train Acc: 83.33% || Test Acc: 83.22%\n",
      "Epoch: 50 || Cost: 0.2382 || Train Acc: 89.67% || Test Acc: 90.91%\n",
      "Epoch: 100 || Cost: 0.1788 || Train Acc: 92.96% || Test Acc: 93.71%\n",
      "Epoch: 150 || Cost: 0.1370 || Train Acc: 96.01% || Test Acc: 96.50%\n",
      "Epoch: 200 || Cost: 0.1158 || Train Acc: 95.77% || Test Acc: 96.50%\n",
      "Epoch: 250 || Cost: 0.1017 || Train Acc: 96.24% || Test Acc: 97.20%\n",
      "Epoch: 300 || Cost: 0.0897 || Train Acc: 96.95% || Test Acc: 97.90%\n",
      "Epoch: 350 || Cost: 0.0826 || Train Acc: 96.95% || Test Acc: 96.50%\n",
      "Epoch: 400 || Cost: 0.0773 || Train Acc: 97.18% || Test Acc: 96.50%\n",
      "Epoch: 450 || Cost: 0.0727 || Train Acc: 97.65% || Test Acc: 95.80%\n",
      "Epoch: 500 || Cost: 0.0687 || Train Acc: 97.65% || Test Acc: 96.50%\n",
      "Epoch: 550 || Cost: 0.0653 || Train Acc: 97.65% || Test Acc: 96.50%\n",
      "Epoch: 600 || Cost: 0.0623 || Train Acc: 97.89% || Test Acc: 96.50%\n",
      "Epoch: 650 || Cost: 0.0596 || Train Acc: 97.89% || Test Acc: 96.50%\n",
      "Epoch: 700 || Cost: 0.0572 || Train Acc: 98.36% || Test Acc: 97.20%\n",
      "Epoch: 750 || Cost: 0.0551 || Train Acc: 98.36% || Test Acc: 96.50%\n",
      "Epoch: 800 || Cost: 0.0531 || Train Acc: 98.36% || Test Acc: 96.50%\n",
      "Epoch: 850 || Cost: 0.0513 || Train Acc: 98.36% || Test Acc: 96.50%\n",
      "Epoch: 900 || Cost: 0.0497 || Train Acc: 98.36% || Test Acc: 96.50%\n",
      "Epoch: 950 || Cost: 0.0482 || Train Acc: 98.36% || Test Acc: 96.50%\n",
      "Epoch: 1000 || Cost: 0.0468 || Train Acc: 98.36% || Test Acc: 96.50%\n",
      "Epoch: 1050 || Cost: 0.0454 || Train Acc: 98.36% || Test Acc: 95.80%\n",
      "Epoch: 1100 || Cost: 0.0441 || Train Acc: 98.59% || Test Acc: 95.80%\n",
      "Epoch: 1150 || Cost: 0.0430 || Train Acc: 98.59% || Test Acc: 95.80%\n",
      "Epoch: 1200 || Cost: 0.0419 || Train Acc: 98.59% || Test Acc: 95.80%\n",
      "Epoch: 1250 || Cost: 0.0409 || Train Acc: 98.59% || Test Acc: 96.50%\n",
      "Epoch: 1300 || Cost: 0.0400 || Train Acc: 98.83% || Test Acc: 96.50%\n",
      "Epoch: 1350 || Cost: 0.0391 || Train Acc: 98.83% || Test Acc: 96.50%\n",
      "Epoch: 1400 || Cost: 0.0383 || Train Acc: 98.83% || Test Acc: 96.50%\n",
      "Epoch: 1450 || Cost: 0.0376 || Train Acc: 98.83% || Test Acc: 95.80%\n",
      "Epoch: 1500 || Cost: 0.0369 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 1550 || Cost: 0.0362 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 1600 || Cost: 0.0355 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 1650 || Cost: 0.0349 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 1700 || Cost: 0.0343 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 1750 || Cost: 0.0338 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 1800 || Cost: 0.0332 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 1850 || Cost: 0.0327 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 1900 || Cost: 0.0321 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 1950 || Cost: 0.0316 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 2000 || Cost: 0.0311 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 2050 || Cost: 0.0306 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 2100 || Cost: 0.0301 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 2150 || Cost: 0.0296 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 2200 || Cost: 0.0292 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 2250 || Cost: 0.0287 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 2300 || Cost: 0.0282 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 2350 || Cost: 0.0278 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 2400 || Cost: 0.0274 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 2450 || Cost: 0.0269 || Train Acc: 99.06% || Test Acc: 95.80%\n",
      "Epoch: 2500 || Cost: 0.0265 || Train Acc: 99.06% || Test Acc: 96.50%\n",
      "Epoch: 2550 || Cost: 0.0261 || Train Acc: 99.06% || Test Acc: 96.50%\n",
      "Epoch: 2600 || Cost: 0.0257 || Train Acc: 99.06% || Test Acc: 96.50%\n",
      "Epoch: 2650 || Cost: 0.0253 || Train Acc: 99.06% || Test Acc: 96.50%\n",
      "Epoch: 2700 || Cost: 0.0250 || Train Acc: 99.30% || Test Acc: 96.50%\n",
      "Epoch: 2750 || Cost: 0.0246 || Train Acc: 99.30% || Test Acc: 96.50%\n",
      "Epoch: 2800 || Cost: 0.0242 || Train Acc: 99.30% || Test Acc: 96.50%\n",
      "Epoch: 2850 || Cost: 0.0239 || Train Acc: 99.30% || Test Acc: 96.50%\n",
      "Epoch: 2900 || Cost: 0.0236 || Train Acc: 99.30% || Test Acc: 96.50%\n",
      "Epoch: 2950 || Cost: 0.0232 || Train Acc: 99.30% || Test Acc: 96.50%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'W1': <tf.Tensor: shape=(5, 30), dtype=float64, numpy=\n",
       "  array([[ 1.22281605, -0.34709099,  0.0441851 , -0.73012135,  1.01101067,\n",
       "           0.66412706,  0.70735601,  0.97763945, -1.53248233, -0.8551321 ,\n",
       "           0.33233017, -0.13288302, -0.99870741,  1.10116511, -0.04393048,\n",
       "          -0.33373319, -0.38381137,  0.11495413,  1.03152692, -0.66610759,\n",
       "           0.90113618,  1.78071192,  2.38113511,  1.6934567 ,  0.89141004,\n",
       "          -1.64587208,  0.82596758, -0.36877805,  0.23068481,  1.29458874],\n",
       "         [-0.05821146, -0.96369363, -0.22641339, -2.32387569, -0.94257449,\n",
       "           0.85890723, -1.73520805,  0.26550869, -0.60778746,  0.24093254,\n",
       "           1.24984618, -0.03302411, -0.93069556, -0.20153626, -0.34123845,\n",
       "           0.44646674,  0.08378925, -0.92181268,  0.79395167, -0.7640713 ,\n",
       "          -1.24994477,  1.42744105, -0.85223774,  0.95741312,  0.96794923,\n",
       "          -0.50670594, -0.82058107, -1.0432927 , -0.27031727, -1.41389373],\n",
       "         [-1.01342593, -1.08366073, -1.27859193, -0.64165961, -0.76962682,\n",
       "           0.98574691, -0.32613046,  0.83310439,  0.19902623, -1.14240433,\n",
       "           0.74221228, -0.19725652,  0.06342621,  0.58249816, -1.79717187,\n",
       "           0.77642719,  1.94097726, -1.94360552, -2.31244325,  0.03524617,\n",
       "          -0.01089838,  1.13302124, -0.19997324,  2.04153206,  0.23720086,\n",
       "           0.58863547, -2.28368666,  0.87317701, -0.40778446, -0.7951016 ],\n",
       "         [-0.05726811, -1.3087194 ,  0.52342758, -0.0444024 ,  0.3117995 ,\n",
       "          -0.58383095, -0.58234578, -0.63380584, -0.34114799,  0.56083786,\n",
       "           0.12882588, -0.12385688, -1.54640654, -1.17943329,  0.06221419,\n",
       "           2.39622297, -0.50545726, -0.08259042,  0.78016562,  0.10314578,\n",
       "          -1.18463881, -0.07592753,  0.67319057, -0.4823402 , -0.1807949 ,\n",
       "          -0.3752805 , -0.86887932, -0.25132256, -1.27246888,  0.59173309],\n",
       "         [ 0.17022363,  0.6790588 , -0.07565234,  1.09184806, -0.36807285,\n",
       "           0.56989683, -2.92141376, -0.78726336, -0.07777001,  0.17193513,\n",
       "          -1.02396791, -1.17553271,  0.29208511,  1.18279056,  0.95627598,\n",
       "           0.27316939, -0.60452781,  0.72668284,  1.49617008, -0.08195278,\n",
       "          -0.18889556,  0.53764431,  0.7140023 , -1.08311864,  2.21130079,\n",
       "           0.64797663,  0.34310284,  1.14972358,  0.26146162,  1.04762226]])>,\n",
       "  'b1': <tf.Tensor: shape=(5, 1), dtype=float64, numpy=\n",
       "  array([[ 0.05041202],\n",
       "         [ 0.0326921 ],\n",
       "         [-0.04488976],\n",
       "         [ 0.14730472],\n",
       "         [ 0.06981968]])>,\n",
       "  'W2': <tf.Tensor: shape=(1, 5), dtype=float64, numpy=array([[-2.745095  ,  1.51927911, -0.88440902,  2.82054285, -0.71311148]])>,\n",
       "  'b2': <tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[-0.00163807]])>},\n",
       " <tf.Tensor: shape=(), dtype=float64, numpy=0.022918606495737945>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn2 = ShallowNN(30, 5, 1, alpha=0.09)\n",
    "nn2.optimize(xtrain, ytrain,validation=(xtest, ytest), epochs=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cost')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAj0UlEQVR4nO3de3hcd33n8fdnRpfR1TfJTmI7lmIrIQ65OwbCpUAJmNImQKE49BK2tFkuaWHpsiRP+9DddCkUuhRos5BQ0pYWaiiU1k8IhJAEllsSK4kT4iSOHdux7DixbNmWZN2l7/4xR/JYGduSrfFIms/reeaZc37nnNH3JGN99Du/c1FEYGZmNl6q2AWYmdn05IAwM7O8HBBmZpaXA8LMzPJyQJiZWV5lxS5gqjQ0NERTU1OxyzAzm1EeeuihfRHRmG/ZrAmIpqYmWltbi12GmdmMIunZYy3zISYzM8vLAWFmZnk5IMzMLC8HhJmZ5eWAMDOzvBwQZmaWlwPCzMzyKvmA6Oob5G/ufpqNbQeLXYqZ2bRS0ICQtEbSZklbJd14nPV+U1JIWpXTdlOy3WZJbypUjcMjwefv2cLDzx4o1I8wM5uRCnYltaQ0cAtwFbAL2CBpfUQ8MW69OuBDwAM5bSuBtcAFwFnADyWdGxHDU11nbWX2P0FX39BUf7SZ2YxWyB7EamBrRGyLiAFgHXBNnvX+AvgroC+n7RpgXUT0R8R2YGvyeVOuLJ2iuiJNV99gIT7ezGzGKmRALAbacuZ3JW1jJF0GLI2I705226lUlymj0wFhZnaUog1SS0oBnwX+5BQ+43pJrZJa29vbT7qW+ky5DzGZmY1TyIDYDSzNmV+StI2qA14K/EjSDuDlwPpkoPpE2wIQEbdFxKqIWNXYmPdutRNSlylzQJiZjVPIgNgAtEhqllRBdtB5/ejCiDgUEQ0R0RQRTcD9wNUR0Zqst1ZSpaRmoAV4sFCF1mXKPQZhZjZOwc5iioghSTcAdwFp4PaI2CTpZqA1ItYfZ9tNkr4JPAEMAR8sxBlMo+oyZbR19BTq483MZqSCPjAoIu4E7hzX9vFjrPvacfOfAD5RsOJy1GXKPUhtZjZOyV9JDVBfVUanxyDMzI7igCB7FtPA0Aj9QwU7imVmNuM4IMiOQYCvpjYzy+WA4EhAdPZ6HMLMbJQDAqirLAfcgzAzy+WAAOqrHBBmZuM5IMgdg/AhJjOzUQ4IPEhtZpaPA4LshXKAL5YzM8vhgADqKsuQ8MVyZmY5HBBAKiVqK8o8BmFmlsMBkfAtv83MjuaASPiW32ZmR3NAJOoyZXT2ugdhZjbKAZGoryqnq989CDOzUQ6IhMcgzMyO5oBIOCDMzI5W0ICQtEbSZklbJd2YZ/n7JP1S0kZJP5W0MmlvktSbtG+U9KVC1gnJU+V6B4mIQv8oM7MZoWCPHJWUBm4BrgJ2ARskrY+IJ3JW+3pEfClZ/2rgs8CaZNkzEXFJoeobry5TxtBI0Dc4QlVF+nT9WDOzaauQPYjVwNaI2BYRA8A64JrcFSKiM2e2Bijan+/1mdE7unqg2swMChsQi4G2nPldSdtRJH1Q0jPAp4E/zlnULOkRST+W9Op8P0DS9ZJaJbW2t7efUrFjDw3yOISZGTANBqkj4paIWA58DPizpHkPcHZEXAp8BPi6pPo8294WEasiYlVjY+Mp1eEehJnZ0QoZELuBpTnzS5K2Y1kHvBUgIvojYn8y/RDwDHBuYcrMcg/CzOxohQyIDUCLpGZJFcBaYH3uCpJacmbfAmxJ2huTQW4knQO0ANsKWGvOU+XcgzAzgwKexRQRQ5JuAO4C0sDtEbFJ0s1Aa0SsB26Q9AZgEDgAXJds/hrgZkmDwAjwvojoKFSt4IcGmZmNV7CAAIiIO4E7x7V9PGf6Q8fY7tvAtwtZ23h1HoMwMztK0Qepp4uaijQp4Rv2mZklHBAJSdRW+qFBZmajHBA56qvKPQZhZpZwQOSoy5T7NFczs4QDIkf2jq4+xGRmBg6Io9RnytyDMDNLOCBy+LnUZmZHOCBy1PuhQWZmYxwQOUZ7EH5okJmZA+IodZkyRgIODwwXuxQzs6JzQOTw7TbMzI5wQOTwDfvMzI5wQOTwLb/NzI5wQOTwQ4PMzI5wQOSoHw2IXvcgzMwcEDmODFK7B2Fm5oDIUe+AMDMbU9CAkLRG0mZJWyXdmGf5+yT9UtJGST+VtDJn2U3JdpslvamQdY7KlKcoS8mD1GZmFDAgJKWBW4A3AyuBa3MDIPH1iLgwIi4BPg18Ntl2JbAWuABYA/zf5PMKSlJyR1f3IMzMCtmDWA1sjYhtETEArAOuyV0hIjpzZmuA0XtcXAOsi4j+iNgObE0+r+Cyz4RwD8LMrKyAn70YaMuZ3wW8bPxKkj4IfASoAF6fs+3947ZdnGfb64HrAc4+++wpKdo9CDOzrKIPUkfELRGxHPgY8GeT3Pa2iFgVEasaGxunpJ563/LbzAwobEDsBpbmzC9J2o5lHfDWk9x2yrgHYWaWVciA2AC0SGqWVEF20Hl97gqSWnJm3wJsSabXA2slVUpqBlqABwtY65i6TLkvlDMzo4BjEBExJOkG4C4gDdweEZsk3Qy0RsR64AZJbwAGgQPAdcm2myR9E3gCGAI+GBGn5R7c7kGYmWUVcpCaiLgTuHNc28dzpj90nG0/AXyicNXlV58po3tgiJGRIJXS6f7xZmbTRtEHqaeb+qpyIqB7wL0IMyttDohx/EwIM7MsB8Q4ozfs80C1mZU6B8Q47kGYmWU5IMap93OpzcwAB8SLuAdhZpblgBhnbAzCPQgzK3EOiHHcgzAzy3JAjJMpT1ORTrkHYWYlzwGRR32Vb7dhZuaAyKMuU+6AMLOS54DIoy5T5gvlzKzkOSDyyN7R1QFhZqXNAZFHXaUPMZmZOSDy8CC1mZkDIq+6TLlPczWzkueAyKMuU0bPwDBDwyPFLsXMrGgKGhCS1kjaLGmrpBvzLP+IpCckPSbpHknLcpYNS9qYvNaP37aQRm+30d3vw0xmVroKFhCS0sAtwJuBlcC1klaOW+0RYFVEXAR8C/h0zrLeiLgkeV1dqDrz8e02zMwK24NYDWyNiG0RMQCsA67JXSEi7ouInmT2fmBJAeuZsHrfsM/MrKABsRhoy5nflbQdy3uB7+XMZyS1Srpf0lvzbSDp+mSd1vb29lMueFR90oPo7HUPwsxKV1mxCwCQ9DvAKuBXcpqXRcRuSecA90r6ZUQ8k7tdRNwG3AawatWqmKp66vzQIDOzgvYgdgNLc+aXJG1HkfQG4E+BqyOif7Q9InYn79uAHwGXFrDWo3gMwsyssAGxAWiR1CypAlgLHHU2kqRLgVvJhsPenPZ5kiqT6QbglcATBaz1KPVV7kGYmRXsEFNEDEm6AbgLSAO3R8QmSTcDrRGxHvgMUAv8mySAnckZS+cDt0oaIRtin4qI0xYQ7kGYmRV4DCIi7gTuHNf28ZzpNxxju58DFxaytuMpT6fIlPuhQWZW2nwl9TEsrMvw3MG+YpdhZlY0DohjOHdRLU+/0FXsMszMisYBcQwti+rYvu8wA0O+H5OZlSYHxDGcu6iWoZFgx/7DxS7FzKwoJhQQkv55Im2zScvCOgAfZjKzkjXRHsQFuTPJjfgun/pypo8VC2tJCZ5+obvYpZiZFcVxA0LSTZK6gIskdSavLmAv8J+npcIiyZSnOXt+NVvcgzCzEnXcgIiIT0ZEHfCZiKhPXnURsSAibjpNNRZNy6I6H2Iys5I10UNMd0iqgeyN9SR9NvfhPrPVeYvq2LG/h/6h4WKXYmZ22k00IL4I9Ei6GPgT4BngqwWrappoWVTL8Eiwrd1nMplZ6ZloQAxFRJB94M/fRcQtQF3hypoezl3kM5nMrHRN9F5MXZJuAn4XeLWkFFBeuLKmh3Maa0inxBafyWRmJWiiPYh3Af3A70fE82Sf7fCZglU1TVSWpVm2oNo9CDMrSRMKiCQUvgbMkfTrQF9EzPoxCIBzF9axZa97EGZWeiZ6JfVvAQ8C7wR+C3hA0jsKWdh0ce6iWp7df5i+QZ/JZGalZaJjEH8KXDH61DdJjcAPgW8VqrDpomVRHSMBz7R3c8FZc4pdjpnZaTPRMYhU7iNBgf2T2HZGGz2TyQPVZlZqJvpL/vuS7pL0HknvAb7LuCfF5SNpjaTNkrZKujHP8o9IekLSY5Luyb34TtJ1krYkr+smukNTrbmhhrKU2OyBajMrMcc9xCRpBbAoIj4q6e3Aq5JFvyA7aH28bdPALcBVwC5gg6T1454t/QiwKiJ6JL0f+DTwLknzgT8HVgEBPJRse2Dyu3hqKspSNDfU+J5MZlZyTtSD+BzQCRAR/x4RH4mIjwDfSZYdz2pga0Rsi4gBYB3ZC+3GRMR9EdGTzN5P9vRZgDcBd0dERxIKdwNrJrZLU+/cRXW+q6uZlZwTBcSiiPjl+MakrekE2y4G2nLmdyVtx/Je4HuT2VbS9ZJaJbW2t7efoJyT17KolrYDPfQO+EwmMysdJwqIucdZVjVVRUj6HbKHkyZ18V1E3BYRqyJiVWNj41SV8yLnLqojArb6eggzKyEnCohWSX84vlHSHwAPnWDb3cDSnPklSdv4z3oD2dNor46I/slse7qcu6gW8D2ZzKy0nOg6iA8D35H02xwJhFVABfC2E2y7AWiR1Ez2l/ta4N25K0i6FLgVWDPuNNq7gL+UNC+ZfyNQtOdPLFtQQ3laPL3XAWFmpeO4ARERLwBXSnod8NKk+bsRce+JPjgihiTdQPaXfRq4PSI2SboZaI2I9WQPKdUC/yYJYGdEXB0RHZL+gmzIANwcER0ns4NToTyd4pyGWl8LYWYlZUJXUkfEfcB9k/3wiLiTcddLRMTHc6bfcJxtbwdun+zPLJRzz6jjkZ2n/SxbM7OiKYmroafCuQtr2XWgl8P9Q8UuxczstHBATFDL6C03fCaTmZUIB8QE+UwmMys1DogJWraghoqylG+5YWYlwwExQemUWNFYy1PPOyDMrDQ4ICbh4qVz2bjzIMMjUexSzMwKzgExCS9rnk9X/xBP7uksdilmZgXngJiEK5rnA7BhR9Gu2TMzO20cEJOweG4Vi+dWOSDMrCQ4ICZpdfN8HtzeQYTHIcxsdnNATNIVTfPZ1z3A9n2Hi12KmVlBOSAmaXVz9gazPsxkZrOdA2KSljfWMr+mgge2OyDMbHZzQEySJK5omucehJnNeg6Ik3BF03zaOnrZc6i32KWYmRWMA+IkvKx5AQAP+jCTmc1iBQ0ISWskbZa0VdKNeZa/RtLDkoYkvWPcsmFJG5PX+kLWOVnnn1lHTUXah5nMbFab0BPlToakNHALcBWwC9ggaX1EPJGz2k7gPcB/z/MRvRFxSaHqOxVl6RSXLZvHhu1+wpyZzV6F7EGsBrZGxLaIGADWAdfkrhAROyLiMWCkgHUUxMua57P5hS4OHB4odilmZgVRyIBYDLTlzO9K2iYqI6lV0v2S3jqllU2BK5qy92Vqfda9CDObnabzIPWyiFgFvBv4nKTl41eQdH0SIq3t7e2ntbiLl86lIp3yOISZzVqFDIjdwNKc+SVJ24RExO7kfRvwI+DSPOvcFhGrImJVY2PjqVU7SZnyNBcvneML5sxs1ipkQGwAWiQ1S6oA1gITOhtJ0jxJlcl0A/BK4Injb3X6XdE0n027D9EzMFTsUszMplzBAiIihoAbgLuAJ4FvRsQmSTdLuhpA0hWSdgHvBG6VtCnZ/HygVdKjwH3Ap8ad/TQtrG6ez9BI8MjOg8UuxcxsyhXsNFeAiLgTuHNc28dzpjeQPfQ0frufAxcWsrapcPmyeaQED2zv4JUrGopdjpnZlJrOg9TTXl2mnPPPrGeDxyHMbBZyQJyiV7c08uCODto6eopdipnZlHJAnKLrrlxGSvDln2wrdilmZlPKAXGKzpxTxdsuXcw3NrSxr7u/2OWYmU0ZB8QU+K+/spyB4RH+4Wfbi12KmdmUcUBMgeWNtay54Ay++otn6eobLHY5ZmZTwgExRT7w2hV09Q3xtQd2FrsUM7Mp4YCYIhcumcOrWxr4yk+30zc4XOxyzMxOmQNiCr3/V5bT3tXPtx/eVexSzMxOmQNiCr1i+QIuXjqXW3+8jaHhGfeICzOzozggppAkPvDa5ezs6OG7v9xT7HLMzE6JA2KKXXX+IlYsrOWLP3qGkZEodjlmZifNATHFUinxR69fwVPPd/nqajOb0RwQBXD1xWex5oIz+OsfbObx3YeKXY6Z2UlxQBSAJD759guZX1PBh7+xkd4Bn/ZqZjOPA6JA5tVU8NfvvJite7v55PeeLHY5ZmaT5oAooFe3NPLeVzXz1V88y31P7S12OWZmk1LQgJC0RtJmSVsl3Zhn+WskPSxpSNI7xi27TtKW5HVdIesspI++6TxeckYdH/3Wo77bq5nNKAULCElp4BbgzcBK4FpJK8etthN4D/D1cdvOB/4ceBmwGvhzSfMKVWshZcrTfG7tJXT2DXHjtx8jwqe+mtnMUMgexGpga0Rsi4gBYB1wTe4KEbEjIh4Dxl92/Cbg7ojoiIgDwN3AmgLWWlAvOaOej615CT98ci9f/PEzxS7HzGxCChkQi4G2nPldSduUbSvpekmtklrb29tPutDT4fdf2cRvXHwWn7lrM3dter7Y5ZiZndCMHqSOiNsiYlVErGpsbCx2Occlic+84yIuWjKX//aNjWx6ztdHmNn0VsiA2A0szZlfkrQVettpK1Oe5su/ezlzqsr5w39qZW9XX7FLMjM7pkIGxAagRVKzpApgLbB+gtveBbxR0rxkcPqNSduMt7A+w5d/bxUHega5/qsP+dkRZjZtFSwgImIIuIHsL/YngW9GxCZJN0u6GkDSFZJ2Ae8EbpW0Kdm2A/gLsiGzAbg5aZsVXrp4Dn/zrkvY2HaQ//Etn9lkZtOTZssvp1WrVkVra2uxy5iUW+7bymfu2sxbLjyTv3zbhcypLi92SWZWYiQ9FBGr8i0rO93F2BEfeO1yUhL/5webeXjnAT77W5fwiuULil2WmRkww89imukk8f7XLuffP3AlmfI07/77+/nU955iYMhPozOz4nNATAMXLZnLd//4Vay9Yilf+vEzvP2LP+PJPZ3FLsvMSpwDYpqorijjk2+/iFt/93J2H+jl177wEz687hF27u8pdmlmVqI8BjHNvOmCM3h58wK+9P+e4R9+tp07HtvDtavP5o9ev4KF9Zlil2dmJcRnMU1jezv7+MK9W1j3YBtlafF7r2ji91/ZzBlzHBRmNjWOdxaTA2IG2LHvMJ/74dOsf/Q50ilx9cWLuf4153DeGXXFLs3MZjgHxCzR1tHDV366nW9saKN3cJjXndfIH7z6HK5cvgBJxS7PzGYgB8Qsc+DwAP9y/7P84893sP/wAM0NNay9Yim/efkSGmori12emc0gDohZqm9wmO89vod/faCNB3d0UJ4Wb7zgDNZesZQrlzeQTrlXYWbH54AoAVv3dvGvD7bx7Yd3cbBnkMa6St5y4Zn8xsVncdnZc30IyszyckCUkL7BYe59ai/rNz7HvZv3MjA0wpJ5VfzGxWdx1cpFXLJkLin3LMws4YAoUZ19g9y96QXWP/ocP926j+GRoKG2gtedt5BfPX8Rr25poKbSl8KYlTIHhHGoZ5AfPb2XHz65lx9t3ktX3xAV6RSrmubxyhUNvGpFAy9dPMfjFmYlxgFhRxkcHmHDjg7ufXIvP926j6ee7wKgPlPGK5Yv4OXnLOCKpvmcf2a9A8NslvPtvu0o5ekUVy5v4MrlDQDs6+7n58/s52db9vHTrfu4a9MLANRVlnHZsnmsbp7P5cvmceHiOT4kZVZC3IOwF9l9sJcN2zt4cEcHG7Z3sGVvNwApwbmL6rj07LlcunQeFy2dw4rGWsrSvuej2UxVtENMktYAnwfSwN9HxKfGLa8EvgpcDuwH3hUROyQ1kX1M6eZk1fsj4n3H+1kOiMLpODzAxrYDbNx5kEfaDvJo20E6+4YAqCxLcf6Z9bx0cT0XLp7DBWfNYcXCWjLl6SJXbWYTUZSAkJQGngauAnaRfbb0tRHxRM46HwAuioj3SVoLvC0i3pUExB0R8dKJ/jwHxOkzMhJs33+YX+46xOO7D/H4c4fYtLuTrv5saKRTormhhpecUcf5Z9Zz3qI6WhbVsmRetcc0zKaZYo1BrAa2RsS2pIh1wDXAEznrXAP8z2T6W8DfyVd0TXuplFjeWMvyxlreeuliIBsaOzt62PRcJ5uf7+SJPV1sbDvIHY/tGduusizFOY21tCysZcXCWs5prOGchlqaG2qoqnCPw2y6KWRALAbacuZ3AS871joRMSTpEDD6UOZmSY8AncCfRcRPxv8ASdcD1wOcffbZU1u9TUoqJZoaamhqqOEtF5051t7ZN8iWF7rYurebrXu72bK3m4d3HmD9o88dtf1ZczI0N9bQtCB5NdTQtKCapfOrfbjKrEim6ykpe4CzI2K/pMuB/5B0QUQc9RzOiLgNuA2yh5iKUKedQH2mnMuXzefyZfOPau8dGGb7vsNs33eYbe3dbN93mGf2HeaOx/ZwqHdwbD0JzqjPcPb8apYtqGbZghqWzq/m7PnVLJ1XxfyaCt9GxKxAChkQu4GlOfNLkrZ86+ySVAbMAfZHdmCkHyAiHpL0DHAu4EGGWaKqIs3Ks+pZeVb9i5Yd7Blgx/4ediQB0tbRw86OHu7b3E57166j1q2uSLNkXhVL5lWzZF4VZ83NvhbPzXDW3CoW1mU87mF2kgoZEBuAFknNZINgLfDuceusB64DfgG8A7g3IkJSI9AREcOSzgFagG0FrNWmkbnVFVxSXcElS+e+aFnPwBBtHb20dfTQdqCHXQey07sO9NK6o2Ps7KpR6ZRYVFfJGXMy2Vd9FWfOybCwvpKFddn3RfUZan19h9mLFOxfRTKmcANwF9nTXG+PiE2SbgZaI2I98BXgnyVtBTrIhgjAa4CbJQ0CI8D7IqKjULXazFFdUcZ5Z9Qd82l63f1D7DnYy+6DvTx3sI/dB3t4/lA/z3f28tTzXfxoczs9A8N5PjdNY10ljbWVNNRWZqfrKllQW8GCmkoaaiuYX1PBgtpK6jNlPqxlJcEXyllJiQg6+4Zo7+pjb2c/L3T18UJnP3s7+2nv7mdfV/Le3c/BnsG8n1GeFvOqs4Exr7qC+bUVzKsuZ351BXOrK5hXU559r65gblU5c6vLqcuU+1CXTUu+1YZZQhJzqsqZU1XOioXHf6b3wNAIB3oG2Nfdz/7uAfYf7mdf1wAdPQMcODzA/sPZ9yf3dNJxeIBDvYMc6+8tKTtgPycJjDlV5dRXlTO36sj0nKpy6jPl1FeVMacqGyr1mTLqMuVUlPlqdTv9HBBmx1BRlmJRfYZF9ZkJrT88EnT2DnKgZ4ADPYMc7BngYM8gB3sHOdQzwMHeQQ72DHKoN/vafaB3bHpo5Pg9+aryNHWZsuSVDZS6TNlYgNRWHllWW5ltr82UJe3ZdSvLUj40ZpPigDCbIumUmFdTwbyaikltFxH0Dg5zqHeQzt4hOvsGOdQzSFd/Mt87SFf/0FhbV98Qh3oH2XWgh66+Ibr6BukbHDnhzylLaSw0xl7j5muSoKkZna4cnU6PLa+tdNiUCgeEWZFJorqijOqKMs6cc3KfMTg8QnffEF192YDp6hvicP8Q3f3ZAOnqHzrS1jdEV/K+v3uAnft76OrPLss3gJ9PWUpjYVFTmaa64sh0TWUZNRVJsFSkqa4sozZnneqK9FgA1STTVeVpP+lwGnJAmM0C5enUSfVexhseCQ4PZMPi8FioDNPdP0h3//BY6Iwu7+4fpmfgSFt7Vz/d/UP0DGS3Gxg+cc9mVHVFNkRGA2c0XKrL01RXpqmpKBtbp7oi23bU/Nh7mqqK7PoOnlPjgDCzMemUsgPlmfIp+byBoZGxAOkZGB7rpXTn9FhGwyS73jC9A0McTto7ewfZc7B3bL2egWH6hyYeOgCZ8hTVSViMhsfodHVFGZmx6fTY9Og6VTnto/NVyXQmmS6fxbe7d0CYWcFUlKWoKMue/jtVhoZH6BkcpjcncHIDpGcgGzK57b2Do+1H3vd1D9Az0EPvwPDY8smGD2QPt2XK08krlQ2PJEQqc+Zzl1Um85myI8syOW2VOW2VZUe/l6V02sZ/HBBmNqOUpVPUp1NT1svJNTKSPWGgd/BImPSNzo9rG31l20foHRyib3BkrK1vcDi55qY/WXdkrP1kgmhUSrwoOC5cMpe/vfbSKfwvkeWAMDNLpJLB90I/WndkJBgYzg2TkbHA6R8aGQuU/qFh+gdH6Bt9z1me+75kXlVB6nRAmJmdZqmUyKSyh5fmFruY45i9oytmZnZKHBBmZpaXA8LMzPJyQJiZWV4OCDMzy8sBYWZmeTkgzMwsLweEmZnlNWseOSqpHXj2FD6iAdg3ReUU22zaF5hd+zOb9gW8P9PZRPdlWUQ05lswawLiVElqPdZzWWea2bQvMLv2ZzbtC3h/prOp2BcfYjIzs7wcEGZmlpcD4ojbil3AFJpN+wKza39m076A92c6O+V98RiEmZnl5R6EmZnl5YAwM7O8Sj4gJK2RtFnSVkk3FrueyZJ0u6S9kh7PaZsv6W5JW5L3ecWscaIkLZV0n6QnJG2S9KGkfabuT0bSg5IeTfbnfyXtzZIeSL5z35A0dQ9sLjBJaUmPSLojmZ/J+7JD0i8lbZTUmrTNyO8agKS5kr4l6SlJT0p6xanuT0kHhKQ0cAvwZmAlcK2klcWtatL+EVgzru1G4J6IaAHuSeZngiHgTyJiJfBy4IPJ/4+Zuj/9wOsj4mLgEmCNpJcDfwX8TUSsAA4A7y1eiZP2IeDJnPmZvC8Ar4uIS3KuF5ip3zWAzwPfj4iXABeT/f90avsTESX7Al4B3JUzfxNwU7HrOon9aAIez5nfDJyZTJ8JbC52jSe5X/8JXDUb9geoBh4GXkb26taypP2o7+B0fgFLkl8yrwfuADRT9yWpdwfQMK5tRn7XgDnAdpITj6Zqf0q6BwEsBtpy5nclbTPdoojYk0w/DywqZjEnQ1ITcCnwADN4f5JDMhuBvcDdwDPAwYgYSlaZSd+5zwH/AxhJ5hcwc/cFIIAfSHpI0vVJ20z9rjUD7cA/JIcA/15SDae4P6UeELNeZP90mFHnMkuqBb4NfDgiOnOXzbT9iYjhiLiE7F/fq4GXFLeikyPp14G9EfFQsWuZQq+KiMvIHmL+oKTX5C6cYd+1MuAy4IsRcSlwmHGHk05mf0o9IHYDS3PmlyRtM90Lks4ESN73FrmeCZNUTjYcvhYR/540z9j9GRURB4H7yB6GmSupLFk0U75zrwSulrQDWEf2MNPnmZn7AkBE7E7e9wLfIRvgM/W7tgvYFREPJPPfIhsYp7Q/pR4QG4CW5EyMCmAtsL7INU2F9cB1yfR1ZI/lT3uSBHwFeDIiPpuzaKbuT6Okucl0FdnxlCfJBsU7ktVmxP5ExE0RsSQimsj+O7k3In6bGbgvAJJqJNWNTgNvBB5nhn7XIuJ5oE3SeUnTrwJPcKr7U+zBlWK/gF8DniZ7bPhPi13PSdT/r8AeYJDsXxHvJXts+B5gC/BDYH6x65zgvryKbBf4MWBj8vq1Gbw/FwGPJPvzOPDxpP0c4EFgK/BvQGWxa53kfr0WuGMm70tS96PJa9Pov/2Z+l1Lar8EaE2+b/8BzDvV/fGtNszMLK9SP8RkZmbH4IAwM7O8HBBmZpaXA8LMzPJyQJiZWV4OCLMTkDSc3PFz9DVlN3CT1JR7J16z6aTsxKuYlbzeyN4uw6ykuAdhdpKS5wl8OnmmwIOSViTtTZLulfSYpHsknZ20L5L0neT5EI9KujL5qLSkLyfPjPhBctU1kv44eTbGY5LWFWk3rYQ5IMxOrGrcIaZ35Sw7FBEXAn9H9m6nAH8L/FNEXAR8DfhC0v4F4MeRfT7EZWSv4AVoAW6JiAuAg8BvJu03Apcmn/O+wuya2bH5SmqzE5DUHRG1edp3kH0g0LbkJoPPR8QCSfvI3oN/MGnfExENktqBJRHRn/MZTcDdkX2gC5I+BpRHxP+W9H2gm+xtE/4jIroLvKtmR3EPwuzUxDGmJ6M/Z3qYI2ODbyH7xMPLgA05d001Oy0cEGan5l05779Ipn9O9o6nAL8N/CSZvgd4P4w9SGjOsT5UUgpYGhH3AR8j+8SwF/VizArJf5GYnVhV8lS4Ud+PiNFTXedJeoxsL+DapO2PyD7Z66Nkn/L1X5L2DwG3SXov2Z7C+8neiTefNPAvSYgI+EJknylhdtp4DMLsJCVjEKsiYl+xazErBB9iMjOzvNyDMDOzvNyDMDOzvBwQZmaWlwPCzMzyckCYmVleDggzM8vr/wPcZHRuv3RIJQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(nn2.losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Train adn Test Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
