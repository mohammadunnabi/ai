{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mathematical expression of the algorithm**:\n",
    "\n",
    "For one example $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(yhat^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(yhat^{(i)}) + (1-y^{(i)} )  \\log(1-yhat^{(i)})\\tag{3}$$\n",
    "\n",
    "The cost is then computing:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(yhat^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "Gradient Computing:\n",
    "- $$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(yhat-Y)^T\\tag{7}$$\n",
    "- $$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (yhat^{(i)}-y^{(i)})\\tag{8}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight and bias initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer(input_dim: int) -> tuple:\n",
    "    w = tf.zeros([input_dim, 1], dtype=tf.float64)\n",
    "    b = 0.0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b = initializer(3)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.transpose(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $z$ for all $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(W: tf.Tensor, b: tf.float64, X: tf.Tensor):\n",
    "    wT = tf.transpose(W)\n",
    "    Z = tf.tensordot(wT, X, axes=1) + b\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.Variable(\n",
    "    [\n",
    "        [2, 4, -3],\n",
    "        [3, 6, -2],\n",
    "        [4, 6, -1]\n",
    "        ], dtype=tf.float64\n",
    ")\n",
    "Y = tf.Variable([1], dtype=tf.float64)\n",
    "tf.tensordot(tf.transpose(W), X, axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = forward(W, b, X)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Funtion\n",
    "compute $sigmoid(z) = \\frac{1}{1 + e^{-z}}$ for $z = w^T x + b$ to make predictions. Use np.exp() or tf.exp()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z: tf.Tensor):\n",
    "    a = 1/(1 + tf.exp(-Z))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = sigmoid(z)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Cost :\n",
    " $J = -\\frac{1}{m}\\sum_{i=1}^{m}(y^{(i)}\\log(yhat^{(i)})+(1-y^{(i)})\\log(1-yhat^{(i)}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Y: tf.Tensor, Yhat: tf.Tensor):\n",
    "    m = Yhat.shape[1]\n",
    "    loss = tf.reduce_sum((Y * tf.math.log(Yhat)) + ((1-Y) * tf.math.log(1-Yhat)))\n",
    "    c = (-1/m) * loss\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cost(Y, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation:\n",
    "- You get X\n",
    "- You compute $yhat = \\sigma(w^T X + b) $\n",
    "- You calculate the cost function: $J = -\\frac{1}{m}\\sum_{i=1}^{m}(y^{(i)}\\log(yhat^{(i)})+(1-y^{(i)})\\log(1-yhat^{(i)}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(W: tf.Tensor, b: tf.Tensor, X: tf.Tensor, Y: tf.Tensor):\n",
    "    Z = forward(W, b, X)      # forward\n",
    "    Yhat = sigmoid(Z)         # activation\n",
    "    cost = compute_cost(Y, Yhat)     # cost\n",
    "    return Yhat, tf.squeeze(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.Variable(\n",
    "    [\n",
    "        [2, 3, 4, 5, 6],\n",
    "        [7, 2, 3, 4, 8],\n",
    "    ], dtype=tf.float64\n",
    ")\n",
    "Y = tf.Variable([[1, 1, 0, 0, 1]], dtype=tf.float64)\n",
    "Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b = initializer(2)\n",
    "Yhat, cost = forward_prop(W, b, X, Y)\n",
    "Yhat, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.squeeze([[[[3.0, 2.0]]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propagation: \n",
    "\n",
    "- $$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(yhat-y)^T\\tag{7}$$\n",
    "- $$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (yhat^{(i)}-y^{(i)})\\tag{8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(X: tf.Tensor, Yhat: tf.Tensor, Y: tf.Tensor) -> dict:\n",
    "    m = Y.shape[1]\n",
    "    loss = Yhat - Y\n",
    "    dW = (1/m) * (tf.tensordot(X, tf.transpose(loss), axes=1))\n",
    "    db = (1/m) * tf.reduce_sum(loss)\n",
    "    return {'dW': dW, 'db':db}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = back_prop(X, Yhat, Y)\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimizer(X: tf.Tensor, Y: tf.Tensor, epochs: int = 100, alpha=0.01):\n",
    "    # initialize params W, b\n",
    "    input_dim = X.shape[0]\n",
    "    W, b = initializer(input_dim)\n",
    "\n",
    "    # iterations\n",
    "    for epoch in range(epochs):\n",
    "        # forward propagation\n",
    "        Yhat, cost = forward_prop(W, b, X, Y)\n",
    "\n",
    "        # back propagation\n",
    "        grads = back_prop(X, Yhat, Y)\n",
    "\n",
    "        # update state\n",
    "        W = W - (alpha * grads['dW'])\n",
    "        b = b - (alpha * grads['db'])\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch: {epoch} => Cost: {cost}\")\n",
    "\n",
    "    return W, b, grads, cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.Variable(\n",
    "    [\n",
    "        [2, 3, 4, 5, 6],\n",
    "        [7, 2, 3, 4, 8],\n",
    "    ], dtype=tf.float64\n",
    ")\n",
    "Y = tf.Variable([[1, 1, 0, 0, 1]], dtype=tf.float64)\n",
    "Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer(X, Y, alpha=0.1, epochs = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X, Y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X = tf.Variable(X.T, dtype=tf.float64)\n",
    "Y = tf.Variable([Y], dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer(X, Y, epochs=10000, alpha=0.09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "- Initialize $$ w,b $$\n",
    "- Forward Propagation:\n",
    "    - You get X\n",
    "    - You compute $yhat = \\sigma(w^T X + b) $\n",
    "    - You calculate the cost function: $J = -\\frac{1}{m}\\sum_{i=1}^{m}(y^{(i)}\\log(yhat^{(i)})+(1-y^{(i)})\\log(1-yhat^{(i)}))$\n",
    "- Back Propagation: \n",
    "    - $$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(yhat-y)^T\\tag{7}$$\n",
    "    - $$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (yhat^{(i)}-y^{(i)})\\tag{8}$$\n",
    "- Update weights:\n",
    "    - $$ w = w - {\\alpha} * \\frac{\\partial J}{\\partial w} $$\n",
    "    - $$ b = b- {\\alpha}  * \\frac{\\partial J}{\\partial b} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    Pass\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int):\n",
    "        self.weights, self.bias = initializer(input_dim=input_dim)\n",
    "\n",
    "    def initializer(input_dim: int) -> tuple:\n",
    "        weights = tf.zeros([input_dim, 1], dtype=tf.float64)\n",
    "        bias = 0.0\n",
    "        return weights, bias\n",
    "\n",
    "    def forward(self, X: tf.Tensor, Y: tf.Tensor):\n",
    "        return tf.tensordot(tf.transpose(self.weights), X, axes=1) + self.bias\n",
    "\n",
    "    def sigmoid(self, Z: tf.Tensor):\n",
    "        return 1/(1 + (tf.exp(-Z)))\n",
    "\n",
    "    def compute_cost(self, X: tf.Tensor, Y: tf.Tensor, Yhat: tf.Tensor):\n",
    "        return (-1/Y.shape[1]) * tf.reduce_sum(Y * tf.math.log(Yhat) + ((1-Y) * tf.math.log(1-Yhat)))\n",
    "\n",
    "    def forward_prop(self, X: tf.Tensor, Y: tf.Tensor):\n",
    "        Z = self.forward(X, Y)\n",
    "        Yhat = self.sigmoid(Z)\n",
    "        self.cost = self.compute_cost(X, Y, Yhat)\n",
    "        return Yhat, tf.squeeze(self.cost)\n",
    "\n",
    "    def back_prop(self, X: tf.Tensor, Y: tf.Tensor, Yhat: tf.Tensor):\n",
    "        m = Yhat.shape[1]\n",
    "        dW = (1/m) * tf.tensordot(X, tf.traspose(Yhat - Y), axes=1)\n",
    "        db = (1/m) * tf.reduce_sum(Yhat-Y)\n",
    "        return {'dW': dW, 'db': db}\n",
    "\n",
    "    def update_weights(self, grads: dict):\n",
    "        self.weights = self.weights - (self.alpha * grads['dW'])\n",
    "        self.bias = self.bias - (self.alpha * grads['db'])\n",
    "\n",
    "    def optimize(self, X: tf.Tensor, Y: tf.Tensor, epochs: int = 1000, alpha=0.001):\n",
    "        self.alpha = alpha\n",
    "        for epoch in range(epochs):\n",
    "            Yhat, self.cost = self.forward_prop(X, Y)\n",
    "            grads = back_prop(X, Y, Yhat)\n",
    "            self.update_weights(grads)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch: {epoch} => Cost: {self.cost}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(30)\n",
    "nn.optimize(X, Y, epochs=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
